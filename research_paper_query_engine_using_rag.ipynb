{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NV6PL2-g1yMU",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install llama-index openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create openAI API key object and set the environment variable.\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "open_ai_key = userdata.get('openai_api_key')\n",
        "os.environ[\"OPENAI_API_KEY\"] = open_ai_key"
      ],
      "metadata": {
        "id": "FCOVqJnW2JTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If running on colab, run this cell to mount your google drive. Also, adjust the database and saved index paths below to point to the correct folder.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "xmusXj-82PmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# database_path = \"/content/drive/MyDrive/research_papers_rag/documents\"  # if running on colab\n",
        "# database_path = \"/home/akshat.pandya/research_papers_q_n_a/example_database\"\n",
        "\n",
        "# index_path = \"/content/drive/MyDrive/research_papers_rag/index\"  # if running on colab\n",
        "# index_path = \"/home/akshat.pandya/research_papers_q_n_a/example_index\""
      ],
      "metadata": {
        "id": "dmM0XIRzRtF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_query_engine(llm, index):\n",
        "  query_engine = index.as_query_engine(llm=llm, response_mode='tree_summarize')\n",
        "  return query_engine"
      ],
      "metadata": {
        "id": "OQVRNS3-Iq2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def query_database(query, query_engine):\n",
        "  response = query_engine.query(query)\n",
        "  return response"
      ],
      "metadata": {
        "id": "j9G3mlSu9sFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and index the documents. Store a local copy of the index. Run this cell only the first time you're indexing the documents.\n",
        "\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
        "\n",
        "documents = SimpleDirectoryReader(database_path).load_data()\n",
        "index = VectorStoreIndex.from_documents(documents)\n",
        "index.storage_context.persist(persist_dir=index_path)"
      ],
      "metadata": {
        "id": "XZNByGI12Zb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the stored index\n",
        "from llama_index.core import StorageContext, load_index_from_storage\n",
        "\n",
        "# rebuild storage context\n",
        "storage_context = StorageContext.from_defaults(persist_dir=index_path)\n",
        "\n",
        "# load index\n",
        "index = load_index_from_storage(storage_context)"
      ],
      "metadata": {
        "id": "nwlSkcLf42MU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms.openai import OpenAI\n",
        "\n",
        "# Define LLM model to use for querying\n",
        "llm = OpenAI(model=\"gpt-4o\")"
      ],
      "metadata": {
        "id": "blrtEyrxNjXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = create_query_engine(llm, index)"
      ],
      "metadata": {
        "id": "JwbGXyHXOCXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(query_database(\"What is the paper Auto-RAG about?\", query_engine))"
      ],
      "metadata": {
        "id": "JbPV0NESOClq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(query_database(\"List the titles of all the papers that implement a new RAG technique. Ignore the papers in the references section.\", query_engine))"
      ],
      "metadata": {
        "id": "cYbLyJv3PVai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(query_database(\"What are the latest advancements in bioenginnering? If the database doesn't have any information about this, please say I don't know.\", query_engine))"
      ],
      "metadata": {
        "id": "gsEbXH--Ps_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4thOYtbPP40t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}